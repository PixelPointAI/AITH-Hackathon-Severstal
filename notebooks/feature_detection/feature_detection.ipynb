{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixelpoint.feature_detection import orb_sift_extract_keypoints_and_descriptors, orb_sift_draw_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = Path.cwd()\n",
    "\n",
    "data_dir = current_dir / 'data'\n",
    "img_1_path = data_dir / 'cam2_1.jpg'\n",
    "img_2_path = data_dir / 'cam1_1.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORB detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(kp1, _), (kp2, _) = orb_sift_extract_keypoints_and_descriptors(img_1_path, img_2_path, detector_type='ORB')\n",
    "\n",
    "print(f\"Keypoints in image 1: {len(kp1)}\")\n",
    "print(f\"Keypoints in image 2: {len(kp2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_sift_draw_keypoints(img_1_path, kp1, img_2_path, kp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIFT detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(kp1, _), (kp2, _) = orb_sift_extract_keypoints_and_descriptors(img_1_path, img_2_path, detector_type='SIFT')\n",
    "\n",
    "print(f\"Keypoints in image 1: {len(kp1)}\")\n",
    "print(f\"Keypoints in image 2: {len(kp2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_sift_draw_keypoints(img_1_path, kp1, img_2_path, kp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SuperPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, SuperPointForKeypointDetection\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixelpoint.feature_detection import load_images, process_images, superpoint_detect_keypoints, superpoint_visualize_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [img_1_path, img_2_path]\n",
    "images = load_images(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(\"magic-leap-community/superpoint\")\n",
    "model = SuperPointForKeypointDetection.from_pretrained(\"magic-leap-community/superpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_results = superpoint_detect_keypoints(images, model, processor)\n",
    "superpoint_visualize_keypoints(image_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1. Использовать SIFT не будем, т.к. скорость его работы низка, да и как видно, при матчинге будет очень много несоответствий.  \n",
    "2. ORB тоже показывает неудовлетворительные результаты, т.к. как видно он не отмечает все точки на объекте равномерно.  \n",
    "3. Метод SuperPoint (на основе нейронной сети) работает значительно лучше - равномерность точек по объекту. Вдобавок к алгоритму поиска ключевых точек SuperPoint существует алгоритм матчинга (от тех же исследователей/разработчиков) который является логичным продолжением этого - [SuperGlue](https://github.com/magicleap/SuperGluePretrainedNetwork/tree/master)\n",
    "\n",
    "Оставшиеся задачи:\n",
    "1. Попробовать другие детекторы на основе DL (D2Net, R2D2)\n",
    "2. Применить последовательно к SuperPoint алгоритм SuperGlue для матчинга точек\n",
    "3. Также остается идея для использования сегментации чтобы отделить сам объект от фона и уже только на нем искать характеристические точки"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack-sev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
