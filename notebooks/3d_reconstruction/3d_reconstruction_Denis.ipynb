{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_RESOLUTION = (5120, 4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the calibration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_calib_data = '/home/deniskirbaba/Git/AITH-Hackathon-Severstal/src/calibration/data/calibration_data_real.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_calib_data, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "calib_data = {}\n",
    "for key, value in data.items():\n",
    "    calib_data[key] = np.array(value)\n",
    "\n",
    "for name, matrix in calib_data.items():\n",
    "    print(f\"Matrix {name}:\\n{matrix}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the stereo image pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _cam1_ - левая камера\n",
    "* _cam2_ - правая камера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam1_imgs_path = \"data/cam2/\"\n",
    "cam2_imgs_path = \"data/cam1/\"\n",
    "img_name = 'real_obj.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam1_img = cv.imread(cam1_imgs_path + img_name, cv.IMREAD_GRAYSCALE)\n",
    "cam2_img = cv.imread(cam2_imgs_path + img_name, cv.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(cam1_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cam2_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R1, R2, P1, P2, Q, validPixROI1, validPixROPI2 = cv.stereoRectify(calib_data['CM'], calib_data['dist'],\n",
    "                                                calib_data['CM'], calib_data['dist'],\n",
    "                                                IMG_RESOLUTION,\n",
    "                                                calib_data['R'], calib_data['T'],\n",
    "                                                flags=0, # cv.CALIB_ZERO_DISPARITY,\n",
    "                                                alpha=-1\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_rotation(R):\n",
    "    sy = np.sqrt(R[0, 0] ** 2 + R[1, 0] ** 2)\n",
    "    singular = sy < 1e-6\n",
    "    if not singular:\n",
    "        yaw = np.arctan2(R[2, 1], R[2, 2])\n",
    "        pitch = np.arctan2(-R[2, 0], sy)\n",
    "        roll = np.arctan2(R[1, 0], R[0, 0])\n",
    "    else:\n",
    "        yaw = np.arctan2(-R[1, 2], R[1, 1])\n",
    "        pitch = np.arctan2(-R[2, 0], sy)\n",
    "        roll = 0\n",
    "    euler_angles_calculated = np.degrees(np.array([yaw, pitch, roll]))\n",
    "    print(f\"Yaw: {euler_angles_calculated[0]:.2f} degrees\")\n",
    "    print(f\"Pitch: {euler_angles_calculated[1]:.2f} degrees\")\n",
    "    print(f\"Roll: {euler_angles_calculated[2]:.2f} degrees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_rotation(R1)\n",
    "show_rotation(R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize undistort and rectification transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam1_map1, cam1_map2 = cv.initUndistortRectifyMap(calib_data['CM'], calib_data['dist'], \n",
    "                           R1, P1, \n",
    "                           IMG_RESOLUTION, cv.CV_32FC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam2_map1, cam2_map2 = cv.initUndistortRectifyMap(calib_data['CM'], calib_data['dist'], \n",
    "                           R2, P2, \n",
    "                           IMG_RESOLUTION, cv.CV_32FC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_epipolar_lines(img1, img2, color=255, step=250):\n",
    "    img1_lines = img1.copy()\n",
    "    img2_lines = img2.copy()\n",
    "\n",
    "    height = img1.shape[0]\n",
    "\n",
    "    for y in range(0, height, step):\n",
    "        cv.line(img1_lines, (0, y), (img1.shape[1], y), color, 7)\n",
    "        cv.line(img2_lines, (0, y), (img2.shape[1], y), color, 7)\n",
    "\n",
    "    return img1_lines, img2_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rectified_cam1_img = cv.remap(cam1_img, cam1_map1, cam1_map2, interpolation=cv.INTER_LINEAR)\n",
    "rectified_cam2_img = cv.remap(cam2_img, cam2_map1, cam2_map2, interpolation=cv.INTER_LINEAR)\n",
    "\n",
    "epipolar_img_left, epipolar_img_right = draw_epipolar_lines(rectified_cam1_img, rectified_cam2_img)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(epipolar_img_left, cmap='gray')\n",
    "plt.title('Rectified Left Camera Image with Epipolar Lines')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(epipolar_img_right, cmap='gray')\n",
    "plt.title('Rectified Right Camera Image with Epipolar Lines')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эпиполярные линии верны, а значит что найденные внутренние и внешние параметры также верны.   \n",
    "Значит мы можем произвести ректификацию изображений, а значит можем и использовать алгоритм BM, SGBM для вычисления диспаритетов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply bluring to reduce noise and improve matching accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_left_img = cv.GaussianBlur(rectified_cam1_img, (5, 5), 0)\n",
    "preprocessed_right_img = cv.GaussianBlur(rectified_cam2_img, (5, 5), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вычисление диспаритетов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### С помощью SGMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGBM Parameters\n",
    "min_disp = -1  # Minimum disparity (typically 0 or a small negative number)\n",
    "num_disp = 12 * 16  # Number of disparities to search (must be divisible by 16)\n",
    "block_size = 13  # Block size to match (the size of the windows for matching)\n",
    "\n",
    "stereo = cv.StereoSGBM_create(\n",
    "    minDisparity=min_disp,\n",
    "    numDisparities=num_disp,\n",
    "    blockSize=block_size,\n",
    "    P1=8 * 1 * block_size ** 2,  # Smoothness penalty (smaller P1)\n",
    "    P2=32 * 1 * block_size ** 2,  # Smoothness penalty (larger P2)\n",
    "    disp12MaxDiff=3,  # Maximum allowed difference in the left-right disparity check\n",
    "    uniquenessRatio=10,  # Margin in percentage by which the best cost function value should \"win\"\n",
    "    speckleWindowSize=100,  # Maximum size of smooth disparity regions to consider them noise\n",
    "    speckleRange=25,  # Maximum disparity variation within each connected component\n",
    "    preFilterCap=50  # Pre-filtering before disparity computation\n",
    ")\n",
    "\n",
    "disparity = stereo.compute(preprocessed_left_img, preprocessed_right_img).astype(np.float32) / 16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity_normalized = cv.normalize(disparity, None, alpha=0, beta=255, norm_type=cv.NORM_MINMAX)\n",
    "disparity_normalized = np.uint8(disparity_normalized)\n",
    "\n",
    "plt.imshow(disparity_normalized, 'gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### С помощью BM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StereoBM parameters\n",
    "num_disp = 6 * 16  # Number of disparities to search (must be divisible by 16)\n",
    "block_size = 9  # Block size to match (should be an odd number, typically between 5 and 21)\n",
    "\n",
    "stereo_bm = cv.StereoBM_create(numDisparities=num_disp, blockSize=block_size)\n",
    "\n",
    "# StereoBM works best with images that have been pre-processed by cv.equalizeHist\n",
    "preprocessed_left_img = cv.equalizeHist(preprocessed_left_img)\n",
    "preprocessed_right_img = cv.equalizeHist(preprocessed_right_img)\n",
    "\n",
    "disparity = stereo_bm.compute(preprocessed_left_img, preprocessed_right_img).astype(np.float32) / 16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity_normalized = cv.normalize(disparity, None, alpha=0, beta=255, norm_type=cv.NORM_MINMAX)\n",
    "disparity_normalized = np.uint8(disparity_normalized)\n",
    "\n",
    "plt.imshow(disparity_normalized, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вычисление points cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = cv.reprojectImageTo3D(disparity_normalized, Q)\n",
    "\n",
    "gray_image = cam1_img\n",
    "\n",
    "# Filter points with valid disparities (mask out points with no disparity)\n",
    "mask = disparity_normalized > disparity_normalized.min()\n",
    "out_points = points[mask]\n",
    "out_intensities = gray_image[mask]\n",
    "\n",
    "out_colors = out_intensities / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points.shape, out_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print ranges of x, y, z\n",
    "\n",
    "x_min, x_max = np.min(out_points[:, 0]), np.max(out_points[:, 0])\n",
    "y_min, y_max = np.min(out_points[:, 1]), np.max(out_points[:, 1])\n",
    "z_min, z_max = np.min(out_points[:, 2]), np.max(out_points[:, 2])\n",
    "\n",
    "print(f\"x range: ({x_min}, {x_max})\")\n",
    "print(f\"y range: ({y_min}, {y_max})\")\n",
    "print(f\"z range: ({z_min}, {z_max})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter points based on X, Y or Z axis (e.g., filtering out distant points)\n",
    "\n",
    "# idx = np.abs(out_points[:, 0]) < 50\n",
    "# out_points = out_points[idx]\n",
    "# out_intensities = out_intensities[idx]\n",
    "\n",
    "# idx = np.abs(out_points[:, 1]) < 50\n",
    "# out_points = out_points[idx]\n",
    "# out_intensities = out_intensities[idx]\n",
    "\n",
    "# idx = np.abs(out_points[:, 2]) < 50\n",
    "# out_points = out_points[idx]\n",
    "# out_intensities = out_intensities[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points.shape, out_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ply(fn, verts, intensities):\n",
    "    ply_header = '''ply\n",
    "format ascii 1.0\n",
    "element vertex %(vert_num)d\n",
    "property float x\n",
    "property float y\n",
    "property float z\n",
    "property uchar red\n",
    "property uchar green\n",
    "property uchar blue\n",
    "end_header\n",
    "    '''\n",
    "    \n",
    "    verts = verts.reshape(-1, 3)\n",
    "\n",
    "    intensities = intensities.reshape(-1, 1) \n",
    "    intensities = np.clip(intensities, 0, 255)  \n",
    "    out_colors = np.hstack([intensities, intensities, intensities]).astype(np.uint8)\n",
    "\n",
    "    verts_with_colors = np.hstack([verts, out_colors])\n",
    "\n",
    "    with open(fn, 'wb') as f:\n",
    "        f.write((ply_header % dict(vert_num=len(verts))).encode('utf-8'))\n",
    "        np.savetxt(f, verts_with_colors, fmt='%f %f %f %d %d %d')\n",
    "\n",
    "write_ply('synthetic_obj_bm.ply', out_points, out_intensities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack-sev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
